{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Colab Default.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "sv9VPqt_N7of",
        "WsfrImKWN-f-",
        "fJWcIFggO6Xe",
        "5hqjRtr9PHmO",
        "yc0CTh2EtYVG",
        "BmHnSNt0t2xP",
        "X1AIW2o6upRk",
        "fnFo7hJGuv6r",
        "Ut9JwNbEs7OD"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNxpevqmMLasaULhPZyzgV4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hjvanniekerk/AGIT/blob/master/Copy_of_Colab_Default.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv9VPqt_N7of",
        "colab_type": "text"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr2VhyMPMDq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu5sa9aqM4wf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch.nn.functional as F\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "import PIL\n",
        "import argparse\n",
        "\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms, models\n",
        "from PIL import Image\n",
        "from collections import OrderedDict\n",
        "\n",
        "print (\"Package Imports Complete\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsfrImKWN-f-",
        "colab_type": "text"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAes6XzRNIkW",
        "colab_type": "text"
      },
      "source": [
        "Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QOcKIdQNGC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download the required data files\n",
        "!wget -cq https://github.com/udacity/pytorch_challenge/raw/master/cat_to_name.json\n",
        "!wget -cq https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip\n",
        "#!rm -r flower_data || true\n",
        "!unzip -qq flower_data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsBO_g5xNRzd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Directories\n",
        "data_dir = 'flowers'\n",
        "train_dir = data_dir + '/train'\n",
        "valid_dir = data_dir + '/valid'\n",
        "test_dir = data_dir + '/test'\n",
        "print(\"Directories set\")\n",
        "\n",
        "data_dir = 'flower_data'\n",
        "train_dir = data_dir + '/train'\n",
        "valid_dir = data_dir + '/valid'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HV1j9n2Of-_",
        "colab_type": "text"
      },
      "source": [
        "### Set Transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCfuPSI4NfaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Define your transforms for the training and validation sets\n",
        "#data_transforms = \n",
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                       transforms.RandomResizedCrop(224),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize(255),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                           [0.229, 0.224, 0.225])])\n",
        "val_transforms = transforms.Compose([transforms.Resize(255),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                           [0.229, 0.224, 0.225])])\n",
        "\n",
        "print(\"Transforms defined\")\n",
        "\n",
        "# TODO: Load the datasets with ImageFolder\n",
        "#image_datasets = \n",
        "train_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
        "#train_data = datasets.ImageFolder(train_dir, transform=data_transforms_train) old\n",
        "test_data = datasets.ImageFolder(valid_dir, transform=test_transforms)\n",
        "val_data = datasets.ImageFolder(valid_dir, transform=val_transforms)\n",
        "\n",
        "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
        "#dataloaders = \n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "TrainLoader = torch.utils.data.DataLoader(train_data, batch_size, shuffle=True) \n",
        "TestLoader = torch.utils.data.DataLoader(test_data, batch_size)\n",
        "ValidLoader = torch.utils.data.DataLoader(val_data, batch_size)\n",
        "\n",
        "print(\"Dataloaders loaded\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJWcIFggO6Xe",
        "colab_type": "text"
      },
      "source": [
        "### Label mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5Dxb8wuOv54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note that length of possible outpouts is 102\n",
        "import json\n",
        "with open('cat_to_name.json', 'r') as f:\n",
        "    cat_to_name = json.load(f)\n",
        "    \n",
        "#Confirm labels\n",
        "print(str(len(cat_to_name)) + \" Features\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hqjRtr9PHmO",
        "colab_type": "text"
      },
      "source": [
        "## Building and training the classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yc0CTh2EtYVG",
        "colab_type": "text"
      },
      "source": [
        "### Load Pretrained Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2wjOK6qO9KR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load a pre-trained network \n",
        "model = models.vgg16(pretrained=True)\n",
        "model.name = \"vgg16\"\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brtnVCJNPBgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Freeze parameters so we don't backprop through them\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhPttcNktigl",
        "colab_type": "text"
      },
      "source": [
        "### Freeze parameters for backpropogation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmHnSNt0t2xP",
        "colab_type": "text"
      },
      "source": [
        "### Define Network Structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pG7sXmiPOUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a new, untrainted feed-forward network as a classifier, using ReLU activations and dropout\n",
        "\n",
        "# Define network\n",
        "dropout = 0.5\n",
        "\n",
        "#Set Nodes\n",
        "fc01=25088 \n",
        "fc02 = 4096\n",
        "fc03 = len(cat_to_name)\n",
        "    \n",
        "classifier = nn.Sequential(OrderedDict([\n",
        "    ('fc1',nn.Linear(fc01, fc02, bias=True)),\n",
        "    ('relu1', nn.ReLU()),\n",
        "    ('dropout', nn.Dropout(dropout)),\n",
        "        \n",
        "    ('fc2',nn.Linear(fc02, fc03, bias=True)),\n",
        "    ('relu2', nn.ReLU()),\n",
        "    \n",
        "    ('output', nn.LogSoftmax(dim=1))]))\n",
        "\n",
        "model.classifier = classifier\n",
        "\n",
        "print(\"Network defined\")\n",
        "print((len(cat_to_name)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a--gaYx4PbmQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Device agnostic code, automatically uses CUDA if it's enabled\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "device"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6n8pQJDTS4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.to(device);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd_VxwC9TXA2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define loss and optimizer\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
        "\n",
        "# Define deep learning method\n",
        "epochs = 5\n",
        "print_every = 40\n",
        "steps = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhSqiJSpTZS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Implement a function for the validation pass\n",
        "def validation(model, testloader, criterion):\n",
        "    test_loss = 0\n",
        "    accuracy = 0\n",
        "    \n",
        "    for ii, (inputs, labels) in enumerate(testloader):\n",
        "        \n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        output = model.forward(inputs)\n",
        "        test_loss += criterion(output, labels).item()\n",
        "        \n",
        "        ps = torch.exp(output)\n",
        "        equality = (labels.data == ps.max(dim=1)[1])\n",
        "        accuracy += equality.type(torch.FloatTensor).mean()\n",
        "    \n",
        "    return test_loss, accuracy\n",
        "print(\"Defined validation function\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBeLfb32swna",
        "colab_type": "text"
      },
      "source": [
        "# Training the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT_9fGQjTd-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the classifier layers using backpropogation using the pre-trained network to get features\n",
        "'''Trainloader = torch.utils.data.DataLoader(train_data, batch_size, shuffle=True) \n",
        "Testloader = torch.utils.data.DataLoader(val_data, batch_size)\n",
        "Validloader = torch.utils.data.DataLoader(val_data, batch_size)\n",
        "'''\n",
        "\n",
        "print(\"Training process initializing .....\\n\")\n",
        "\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    model.train() # Technically not necessary, setting this for good measure\n",
        "    \n",
        "    for ii, (inputs, labels) in enumerate(TrainLoader):\n",
        "        steps += 1\n",
        "        \n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward and backward passes\n",
        "        outputs = model.forward(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        if steps % print_every == 0:\n",
        "            model.eval()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                valid_loss, accuracy = validation(model, ValidLoader, criterion)\n",
        "            \n",
        "            print(\"Epoch: {}/{} | \".format(e+1, epochs),\n",
        "                  \"Training Loss: {:.4f} | \".format(running_loss/print_every),\n",
        "                  \"Validation Loss: {:.4f} | \".format(valid_loss/len(TestLoader)),\n",
        "                  \"Validation Accuracy: {:.4f}\".format(accuracy/len(TestLoader)))\n",
        "            \n",
        "            running_loss = 0\n",
        "            model.train()\n",
        "\n",
        "print(\"\\nTraining process is now complete!!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjqrHfO4ukb2",
        "colab_type": "text"
      },
      "source": [
        "### Testing your network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LACsgFkEmh6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Do validation on the test set\n",
        "# Do validation on the test set\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for data in trainloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy achieved by the network on test images is: %d%%' % (100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1AIW2o6upRk",
        "colab_type": "text"
      },
      "source": [
        "### Save the checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eG1fn8Hcn3YO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Save the checkpoint \n",
        "# Create this `class_to_idx` attribute quickly\n",
        "model.class_to_idx = train_data.class_to_idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4XJbfaTn57F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = {'architecture': model.name,\n",
        "             'classifier': model.classifier,\n",
        "             'class_to_idx': model.class_to_idx,\n",
        "             'state_dict': model.state_dict()}\n",
        "\n",
        "torch.save(checkpoint, 'my_checkpoint.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnFo7hJGuv6r",
        "colab_type": "text"
      },
      "source": [
        "### Loading the checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDaqiByln8Rm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Write a function that loads a checkpoint and rebuilds the model\n",
        "# Write a function that loads a checkpoint and rebuilds the model\n",
        "def load_checkpoint():\n",
        "    \"\"\"\n",
        "    Loads deep learning model checkpoint.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Load the saved file\n",
        "    checkpoint = torch.load(\"'my_checkpoint.pth\")\n",
        "    \n",
        "    # Download pretrained model\n",
        "    model = models.vgg16(pretrained=True);\n",
        "    \n",
        "    # Freeze parameters so we don't backprop through them\n",
        "    for param in model.parameters(): param.requires_grad = False\n",
        "    \n",
        "    # Load stuff from checkpoint\n",
        "    model.class_to_idx = checkpoint['class_to_idx']\n",
        "    model.classifier = checkpoint['classifier']\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "\n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut9JwNbEs7OD",
        "colab_type": "text"
      },
      "source": [
        "### Inference for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3WrL7U6oPLm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_image(image):\n",
        "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
        "        returns an Numpy array\n",
        "    '''\n",
        "\n",
        "    test_image = PIL.Image.open(image)\n",
        "\n",
        "    # Get original dimensions\n",
        "    orig_width, orig_height = test_image.size\n",
        "\n",
        "    # Find shorter size and create settings to crop shortest side to 256\n",
        "    if orig_width < orig_height: resize_size=[256, 256**600]\n",
        "    else: resize_size=[256**600, 256]\n",
        "        \n",
        "    test_image.thumbnail(size=resize_size)\n",
        "\n",
        "    # Find pixels to crop on to create 224x224 image\n",
        "    center = orig_width/4, orig_height/4\n",
        "    left, top, right, bottom = center[0]-(244/2), center[1]-(244/2), center[0]+(244/2), center[1]+(244/2)\n",
        "    test_image = test_image.crop((left, top, right, bottom))\n",
        "\n",
        "    # Converrt to numpy - 244x244 image w/ 3 channels (RGB)\n",
        "    np_image = np.array(test_image)/255 # Divided by 255 because imshow() expects integers (0:1)!!\n",
        "\n",
        "    # Normalize each color channel\n",
        "    normalise_means = [0.485, 0.456, 0.406]\n",
        "    normalise_std = [0.229, 0.224, 0.225]\n",
        "    np_image = (np_image-normalise_means)/normalise_std\n",
        "        \n",
        "    # Set the color to the first channel\n",
        "    np_image = np_image.transpose(2, 0, 1)\n",
        "    \n",
        "    return np_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tYl7PZHoMvb",
        "colab_type": "text"
      },
      "source": [
        "Image Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olSgQKzBoS9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(image, ax=None, title=None):\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    \n",
        "    # PyTorch tensors assume the color channel is the first dimension\n",
        "    # but matplotlib assumes is the third dimension\n",
        "    image = image.transpose((1, 2, 0))\n",
        "    \n",
        "    # Undo preprocessing\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    image = std * image + mean\n",
        "    \n",
        "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
        "    image = np.clip(image, 0, 1)\n",
        "    \n",
        "    ax.imshow(image)\n",
        "    \n",
        "    return ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DMFWNttoWNW",
        "colab_type": "text"
      },
      "source": [
        "Class Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5igufk9koYGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test functions on an example\n",
        "imshow(process_image(\"flowers/test/10/image_07090.jpg\"));"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEJSBj0doaC_",
        "colab_type": "text"
      },
      "source": [
        "Sanity Checking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpnVjByEocpv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}